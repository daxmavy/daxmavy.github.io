---
title: "Sometimes, the AI isn't the ethical issue - the product is the issue: Ethical AI in business, part 4"
collection: takes
type: "takes"
permalink: /takes/2020-07-26-take4
---
tech is not value-neutral - and neither is apathy

Many of the coolest parts of AI are also the bits with the most danger
- Predictive analytics is often more concerned with accuracy than anything else
- Unsupervised techniques leave a frightening amount of decision-making to algorithmic whimsy, and lend themselves nicely to reductionist characterisations of populations
- Deep learning is entirely unpenetrable: it works, and we have not that many real ideas why. When it starts to reflect the biases deeply engrained in our 

This is a topic for another hot take, but I think that there's a growing recognition that the greatest drivers of value in data science are often not the shiny ML tricks themselves, but rather whatever methods are need to improve customer and user outcomes - including considerations of fairness and ethics. 

Nonetheless, as a maths student and data scientist, it is still disappointing to be told 'you can't play with those toys'

So what can data scientists do?
----------
- not work on shit projects / areas:
    - egs: image recognition; surveillance, promoting addictive behaviours ('sticky' products), predictive policing
- make space for voices that are diverse in two sense:
    - groups from minority communities, both as employees, and as users (or used...)
    - different academic communities: human-computer interaction, sociology
- raise their voices at work: tech workers are uniquely positioned!
- especially if they're practitioners, describe the difficulties in implementing ethics research in AI!
- donate: tech is rewarded richly, and giving back should be a consideration for anyone earning a decent wage in a developed nation. link to effective altruism

The false alternative: 'it's too hard' 
===========

- a universal retreat from 'big data': 
    Perhaps people might say, " well, seems like we should just give up on this whole AI thing"
    but then: just return to hidden discrimination.
    just putting a human in charge 

- don't let this turn into another m'fucking culture war pls
- 

Conclusion
==========

Positive signs:
- my experience at CBA
- greater engagement and awareness in community
- as earlier, this is actually an exciting opportunity to bring issues to light that haven't been brought up before the data revolution!
- tech has demonstrated its ability to listen to and address the needs of majority (esp. wealthy) people. This user-centric approach can be used to focus on the voices of minority groups to bring about the required change.

There is a great deal of optimism, energy, and cautious awareness of the complexity of the issues. We can't wait until the philosophers stop arguing about whether utilitarianism or virtue ethics is better - the process of operationalising ethical considerations in machine learning is happening now. 

There are complexities in this process, and I have outlined some of them above:
1. difficulties with coming up with precise definitions
2. complexity of linking ethics to quantitative data
3. scaling ethical AI in an organisation
4. the tension 