---
title: "Scaling Ethical AI is hard: Ethical AI in business, part 3"
collection: takes
type: "takes"
permalink: /takes/1998-07-26-take3
---

## 3. Solving the 'ethics' problem for one model is easy. Solving it for 500 legacy models in an organisation is not.

- lots of the AI ethics literature amounts to designing a regularisation term, which is added to the utility (or loss) function, and which penalises unfairness according to some definition, and given weight in a way chosen to reflect the ideal balance between accuracy and fairness. This does not reflect the reality of any large-scale ML tool - there is often not a single utility function

- Suppose that you make senior people responsible for specifying what constitutes an acceptable business reason for discrimination. Suppose also that there are 100 models in production under the umbrella of a single such 'responsible person'. How can they deal with this huge workload? they can't do it effectively by themselves. certainly, corporations have gotten very good at scaling solutions to complicated problems - but it's not clear 

- different ethical principles butt into one another: if your organisation doesn't ever find out what someone's race is, then it can never find out whether it's racially discriminatory. However, this data is often *not* captured for a) privacy reasons, b) security issues and c) legitimate fears of its misuse 

- from an organisation design perspective, who do you make responsible for ethical AI? 
  - Data scientists often don't have the right tools or experience - but neither do lawyers. 
    - in fact, this is a *really* unusual intersection of skills
  - Just adding another layer of Risk Management is a possibility - but this usually bureaucratic process doesn't fit in with the agile and iterative process of software development.
  - Making everyone responsible for the problem usually means that no-one is
- The main incentive for workers are their KPIs. But how do you define KPIs for algorithmic ethics in a way that is both meaningful and measurable? goodhart's law

- end-to-end problem: good luck analysing the whole pipeline (especially if there are humans, eg customer service reps). Because it is an end-to-end problem, it touches on many different parts of the organisation - usually more parts than can be ordinarily considered in a single project.

- top-down problem: because a) these decisions are consequential and can land you in the news and b) require touching many different parts of the organisation, high-level decision-makers should usually be responsible, or at least highly involved in, that task. [gradient](https://gradientinstitute.org/blog/4/)
    - but they usually aren't technical! what to do...