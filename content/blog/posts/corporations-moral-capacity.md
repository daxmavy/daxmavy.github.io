---
title: "Dealing with corporations' ability to undermine their own moral capacity"
date: 2025-06-24
draft: false
---

*The following is an essay that I submitted to apply for several graduate courses.*

Short of hitting themself quite hard in the head, a human cannot easily adjust their capacity for moral judgement. In contrast, some non-human 'self adjusting' agents, such as corporations, are able to alter their moral capacities. If removing their moral capacity allows them to escape the harsh sanctions that accompany moral responsibility, what is to stop corporations from doing so? At its simplest, my argument is that if we punish companies more severely when they are aware of the wrongful consequences of their actions - such as Instagram's internal reporting about its harms on teen mental health (Wells, Horwitz, and Seetharaman 2021) - then their self-interested response will be to remove internal research into such topics.

This essay is structured as follows. I first describe the account of moral responsibility that I am using. I then define self-adjusting agents and explain why they will degrade their moral capacities, with corporations as the chief example. I present an argument that this indicates that our responsibility practices need to be altered, and consider options to repair this problem. My most surprising suggestion is that we ought to reverse common-sense intuition by imposing harsher sanctions on self-adjusting agents which lack moral capacity than those which possess moral capacity. I conclude by describing and responding to possible objections.

### Agency and moral responsibility

An agent is an entity which is able to perceive the world, intervene in the world via their actions, and whose actions are guided by some goal state for the world. This functional description of agents is satisfied by many inanimate objects (for example, a thermostat aiming to control the temperature). We require something more for an agent to be morally responsible.

Moral responsibility for an action can mean different things. It might imply that certain sanctions or rewards are appropriate ('accountability'), that the action speaks to the agent's moral character ('attributability'), or that the agent is liable to provide an explanation ('answerability') (Shoemaker 2011). In this essay I focus on responsibility-as-accountability: if an agent is morally responsible for a wrongful action (or 'blameworthy'), then they are an appropriate target for sanctions. This might justify legal sanctions or less formal responses such as shunning a person - or boycotting a company.

To be morally responsible, an agent must have a) adequate control over its actions and b) sufficient moral capacity. I focus on the latter in this essay. Moral capacity is composed of three components. Firstly, the agent must be able to understand the factual consequences of their actions ('factual awareness'). Secondly, the agent must be able to reason about the moral nature of those consequences ('moral reasoning'). Finally, the agent needs to respond to moral reasons and have their decision-making be guided by them, and not merely by the threat of sanction ('reason-responsiveness'). Moral responsibility is often described as requiring actual factual knowledge and actual moral awareness. My focus on the capacity for factual knowledge and capacity for moral awareness might be controversial. My argument does not rely on this 'capacitarian' definition (because it results in a strictly wider ascription of moral responsibility), but it does clarify the presentation and strengthen my conclusions, because they apply to a broad range of definitions of moral responsibility. See (Talbert 2024; Rudy-Hiller 2022) for a more detailed discussion.

### Self-adjusting agents and moral responsibility

A self-adjusting agent is an agent:

1. whose moral capacity may permanently and reversibly change, including potentially losing it entirely ('variability')
2. who possesses the ability to improve and degrade their own moral capacity ('self-alteration')
3. who lacks an irresistible internal factor forcing moral development ('no maturation')

By reversible, I mean that any change is possible to undo. By permanent, I mean that there is no factor promoting reversal to the state prior to the change. To give an example, toppling a Jenga tower is permanent and reversible. It will stay toppled if left alone, but someone can put it back together again.

I now describe the consequences of self-adjusting agents on our responsibility practices. A 'common-sense' view of moral responsibility is that it guides the severity of sanctions. If an agent is morally responsible for a wrongful action, then they deserve harsher sanctions than if they were not morally responsible. At the very least, this may be argued in the following way: if agent A and B both do an identical wrongful action x, are identical in every other way, but agent A is morally responsible and B is not, then both have done x, but A has committed the additional wrongful action of disregarding a moral norm. Hence, it deserves harsher sanction than B.

If being morally responsible implies harsher sanctions for wrongful actions, and wrongful actions would sometimes be in agents' self interest, then they would recognise that having moral capacity is not in their self interest. Because of the 'no maturation' condition, no factor opposes this self-interested calculation. Hence, agents who already possess moral capacity would remove it, and those without would not develop it. More wrongful actions would occur as a result. Agents lacking factual awareness or moral reasoning would not know that they ought to avoid wrongful actions. Agents lacking reason-responsiveness would commit wrongful actions if they thought they could evade sanction.

If we believe that responsibility practices should reduce the likelihood of wrongful actions, and so practices which lead to less wrongful actions are preferable (all else being equal), then we ought to seek out ways to avoid this reduction in moral capacity. But first we need to ask: do self-adjusting agents actually exist? I firstly argue that humans are not self-adjusting agents, then argue that some corporations are self-adjusting agents.

### Human are not self-adjusting agents

Humans do not satisfy any of the requirements of self-adjusting agents. Injury might permanently damage their moral capacities, but this is not reversible. They may intoxicate themselves and so have degraded moral reasoning abilities for a period of time, but this is not permanent.

Humans might try to forget about an inconvenient moral consideration, but in doing so they avoid the exercise of their moral capacity, rather than degrade it. If prompted, they would be able to appreciate the significance of the moral consideration. Humans may try to cultivate certain habits of thinking, leading to some change in their moral capacity, but these only afford the human a limited degree of control over their moral capacity.

Biological maturation and socialisation forces most humans to develop moral capacity. The ascription of moral responsibility to (almost all) adults reflects our faith in this force. Those adult humans who do have extremely limited moral capacity, such as psychopaths, do not do so by choice, and are not able to restore their moral capacity.

### Some corporations are self-adjusting agents

I largely follow List and Pettit's account of group agents (List and Pettit 2011; List 2021). Group agents emerge from sufficiently organised groups of people, with corporations being the canonical example. They are made up of organisational structures (such as disciplinary and decision-making systems), and form internally consistent goals.

Imputing agency and intention on the part of corporations is useful for explaining and understanding their behaviour. This is why it is so frequently done in economics, law and other social sciences (eg Keane 2022). Just as how we ascribe intentionality to humans, regarding them as more than just a bundle of cells, we similarly adopt an 'intentional stance' towards such groups and regard them as agents (Dennett 1989). Moreover, ascribing moral responsibility to corporations usefully avoids 'responsibility gaps'. If we are not able to assign responsibility to a corporation for a wrongful action, we may not be able to assign responsibility to anyone, because each individual's contribution to the final harm may be very indirect or they are coerced by the corporate structure. See (List and Pettit 2011) or de Haan (2021) for more on this.

Under what conditions might corporations be morally responsible? Recall that moral responsibility requires adequate control over actions, as well as sufficient moral capacity. I put aside the control requirement, and focus on moral capacity, which depends on their internal structures. Information gathering and reporting systems provide factual knowledge about the consequences of their actions; decision-making structures such as ethics committees provide moral reasoning ability and guide their actions according to moral reasons.

Having argued for the possibility of corporate moral responsibility, we may now determine whether some corporations are self-adjusting agents. The aforementioned internal structures which determine moral capacity can be improved and degraded, including by the corporation itself, and so the 'variability' and 'self-alteration' conditions for self-adjusting agents are met. It might be argued that corporations' human members might provide an irresistible internal factor promoting moral capacity (de Haan 2023). However, this internal factor is not nearly as strong as the biological factors promoting moral capacity in humans, and may be resisted in a manner unavailable to humans. This provides the 'no maturation' condition. Perhaps some corporations might have particularly good structures for embodying the moral values of their employees. Such cases might fail the 'no maturation' condition, and we exclude them from consideration for the rest of this essay.

Moving from abstract self-adjusting agents to concrete corporations clarifies the harmful impact of losing moral capacity. Corporations which lack systems for perceiving harms or escalating information stumble into abetting atrocities - such as Facebook's role in the Myanmar Rohingya genocide (Kissane 2023). Corporations which lose their reason-responsiveness are psychopathic yet sophisticated agents. If regulations exist, they are regarded as optional constraints to be manipulated via lobbying. If regulations do not exist, then 'self-governance' is guided by self-interested reputational, rather than moral, reasons.

I will now consider how we might redesign our responsibility practices to avoid this problem.

### Obligation to achieve appropriate moral capacity

Improving one's own moral capacity is typically seen as a good thing to do, but not as an obligation. Humans are usually not sanctioned for failing to improve their moral capacity. Briefly, this is because a) altering moral capacity is difficult and b) it might be unfair to sanction a human for failing to do something that they were unaware they ought to (or could) do.

The situation is different for corporations. Firstly, they can relatively easily increase their moral capacity. Secondly, we don't care about the rights of a corporation beyond the benefits such 'rights' provide to humans. Hence, it does not matter if we are 'unfair' to a corporation, if doing so promotes moral capacity in corporations and therefore better outcomes for humans.

Hence, I think that corporations plausibly have an obligation to achieve 'appropriate' moral capacity. Corporations whose actions are more consequential, or have more organisational resources to draw upon, require a higher level of moral capacity to be deemed 'appropriate'.

We might hope that this obligation to achieve appropriate moral capacity would incentivise corporations to improve their moral capacity. However, we run into the same problem as before. We have introduced a new obligation (a 'duty to achieve appropriate moral capacity'), but agents without the moral capacity to appreciate even this obligation would evade moral responsibility and therefore sanction. Hence, a self-interested agent might remove its moral capacity even more aggressively than before. If so, the problem that I set out to solve would only be worsened. This insufficiency leads us to the next two options, which seek to incentivise corporations to develop their moral capacity, without relying on corporations' existing moral responsibility as the basis for such incentives.

### Minimal moral capacity as a requirement of incorporation

We could force some or all corporations to be moral agents by making having the needed moral capacity a requirement for incorporation. This solution has been proposed previously, although without much detail (Donaldson 1982; List 2021). However, the type and level of moral capacity required varies significantly from one company to the next - a shipping company would have to consider very different scenarios to an internet company. Moreover, a large issue for corporations are 'unknown unknowns' - areas where proactive development of moral capacity is required to detect unfamiliar harms. It seems unrealistic to require in advance, as a 'licence to exist', the moral capacities needed to consider these 'unknown unknowns'.

I propose a limited version: requiring corporations to have the minimal moral capacity needed to understand the previously-described obligation to achieve appropriate moral capacity. This requirement would not be a moral obligation but a legislated requirement of incorporation. This solves the problem from the previous section, by ensuring that every corporation has the base level of moral capacity needed to appreciate its obligation to further improve its moral capacity (for example, by investing in investigation teams to try to uncover 'unknown unknowns'). Notably, this is also a generic requirement, which can be easily imposed across industries.

### Imposing sanctions on self-adjusting agents without moral capacity

Even if we impose an obligation to achieve appropriate moral capacity, this does not guarantee conformance. Faced with an agent which did a wrongful action but lacks the moral capacity needed to be morally responsible, how should we respond?

Recall that our problem - corporations degrading their own moral capacity - occurs when corporations seek to evade the harsher sanctions that accompany moral responsibility. This suggests a potential solution: impose sanctions for wrongful actions, regardless of the moral capacity of the agent.

Consider corporations A (with appropriate moral capacity) and B (without appropriate moral capacity), which have both done an identical wrongful action x. The combined effect of the above three suggestions (creating an obligation to achieve appropriate moral capacity, ensuring that corporations appreciate this obligation, and imposing sanctions for wrongful actions regardless of moral responsibility) is that A would experience *harsher* sanction than B. This is because A and B receive identical sanctions for x, but A has done an additional wrong (and deserves additional sanctions) by breaching its obligation to achieve appropriate moral capacity. Hence, self-interested corporations would now be incentivised to improve their moral capacity, and we have solved our initial problem.

This proposal (sanction without responsibility) in a legal context is simply the concept of strict liability, and I refer to it as such from here on. Strict liability is typically defended on economic grounds, aiming to impose the cost of negative externalities on corporations even when they are not negligent. My argument provides an interesting alternative justification for imposing sanction-without-responsibility. Rather than adopting a purely economic cost/benefit analysis, it is precisely because I view corporate moral capacity as important and seek to encourage its development, that I impose sanctions in this manner.

### Relation to existing work

As far as I can tell, the idea of corporations (or agents generally) being able to undermine their moral capacity and so avoid moral responsibility has only been previously addressed in the philosophy literature by de Haan (2023), although he does not use my terminology of 'self-adjusting agents'. De Haan has a different focus, aiming to investigate whether the loss of moral responsibility by what I call self-adjusting agents leads to the undesirable 'responsibility gaps' which motivated the philosophical development of the concept of corporate moral responsibility in the first place. He describes a situation where self-adjusting agent A degrades its moral capacity. He argues that A may in the future be able to be held responsible for this failure, but that during the period of its moral incapacity, it cannot be held responsible as a moral agent, and instead should be treated as an object of policy. In response to the concern that the agent may avoid ever regaining moral capacity, he states that another agent might intervene to force this. The *possibility* of restoring moral responsibility after such intervention is sufficient to allay his concerns about responsibility gaps.

This account is consistent with my argument in this essay. However, de Haan does not investigate my primary concern, which is focused on avoiding incentives for corporations to reduce their moral capacity. Although I agree with his conclusion that there is a possibility of restoring moral responsibility to a corporation via outside intervention, this conclusion does not relieve my concern about the incentives that corporations face in developing their moral capacity.. My proposed alterations to how we sanction corporations aim at avoiding the loss of moral capacity in the first place, as well as describing how we might ensure that outside interventions actually occur to restore moral capacity, when needed.

### Possible objections

There are a range of possible objections to my argument. In summary, they are: that corporate moral agency is not possible or desirable; that the obligation to achieve an appropriate level of moral agency itself fails the moral capacity requirement of moral responsibility; that corporations would respond differently to how I describe; that instrumental justification is an inappropriate basis for evaluating responsibility practices; and finally that my proposals would have negative side effects which overwhelm their benefits.

### Objections about possibility or desirability of corporate moral responsibility

Firstly, it may be argued that corporate moral agency is not possible or desirable. Debate about whether corporations may have agency is well-trodden ground, so I leave the reader to consider the existing arguments in the literature (Pettit 2014; Quinton 1976; Moen 2023).

More directly relevant to my argument, it may be argued that corporations do not satisfy reason-responsiveness, and thus cannot be held morally responsible. Corporations may be factually aware of the consequences of their actions and have the moral reasoning ability to determine that such actions might be morally wrong, without their decision-making being guided by such reasoning. I already described earlier how corporations which lack reason-responsiveness would avoid wrongful actions only insofar as they see the possibility of being caught, and the resulting sanctions, as being more costly than the profit such actions might bring. Under this objection, one might argue either that it is impossible for corporations to maintain reason-responsiveness due to competitive pressures or their profit-seeking structure (in which case ascribing moral responsibility to them is impossible) or that corporations so strongly tend towards this behaviour that attempting to sway them towards acting morally is a fool's errand. I believe that the first objection unduly accepts the Friedmanite conception (1970) of corporations as actors who *can only be expected to* act in a psychopathic manner. Perhaps most or almost all modern corporations might lack reason-responsiveness, but this is not a reason to dismiss its possibility or value. See Hindriks (2018) for a more detailed formulation of the conditions under which a corporation might validly achieve responsiveness-to-reasons, and moral responsibility more generally. The latter objection relates to an issue I raise below, and so will address it there.

An alternative objection might take issue with my argument for why we may ascribe an obligation to corporations to maintain an appropriate level of moral capacity. I argued that since corporations are not moral patients, it does not matter if we are unfair to them. The potential 'unfairness' is occasioned by an obligation for corporations to build a greater level of moral capacity than they currently have - an expectation which the corporation might not reasonably be able to comprehend while they are still at the 'lower' level of moral capacity. This argument in isolation is mostly uncontroversial (cf. Collins 2023). The reader may object, however, that my argument about unfairness elides something more fundamental about moral responsibility. In particular, the corporation may not have the moral capacity needed to comprehend the obligation to build appropriate moral capacity (as I defined it above). If so, then it would fail a requirement for moral responsibility with respect to this particular obligation. This concern is exactly addressed, however, by the section on 'Minimal moral capacity', where I argue for legislating the minimal level of moral responsibility needed to comprehend the obligation to achieve the appropriate level of moral capacity.

### Objections about my characterisation of how corporations would respond to incentives

One might object to my description of how corporations respond to incentives in two ways. Firstly, we might argue that my proposals merely shift the target for manipulation by corporations. In particular, if being a 'self-adjusting agent' leads to sanction without responsibility, corporations may try to avoid being labelled as a self-adjusting agent. As described earlier, it would not be harmful if they violated the 'no maturation' condition. However, if corporations deliberately hamstrung their ability to adjust their own moral capacity, or somehow completely removed the ability for their moral capacity to change in general, then they would no longer be subject to my proposals, and would be locked in to their current (potentially low) level of moral capacity. A possible response to this objection might be to adopt a 'capacitarian' approach also the classification of a corporations as self-adjusting: a corporation is self-adjusting if it possesses the ability to satisfy the variability and self-alteration conditions, and does satisfy the 'no maturation' condition. The full details and possibility of this approach I leave as an open question.

A second possible 'response to incentives' objection is that corporations might respond to my system of sanctions not by developing actual moral capacity, but instead only the facsimile of it. This is somewhat similar to the objection above about the possibility or likelihood of genuine responsiveness-to-reasons, and is a valid concern. Certainly, as highlighted throughout this essay, corporations are likely to respond to sanction-based incentives by tightly acting in their self interest. I rebut this objection, however, by pointing out that my proposals are not designed to ensure that corporations develop genuine moral capacity, but instead to remove a current strong incentive for them to remove it, by imposing sanctions regardless of the (perceived) moral responsibility of the corporation. This objection correctly identifies that my proposals are not a panacea, but it does not undermine the benefits I focus on. I would additionally argue that once the incentive to remove moral capacity is itself removed, some of the internal forces promoting moral development in corporations might be able to promote genuine development of moral capacity.

### Objections about how I evaluate responsibility practices

Finally, it is possible to object to either the appropriateness of instrumentally evaluating responsibility practices, or whether my proposals actually promote less wrongful harms and common welfare in general. Firstly, it is possible to argue that holding an agent responsible is apt (or appropriate) without arguing that we *ought* to do so. Adopting this strictly 'backwards-looking' view of responsibility practices allows philosophers to avoid having to directly consider their practical consequences. This view is entirely incompatible with my argument, which heavily relies on how responsibility practices influence agents' incentives. I would point out, however, that the flurry of research into responsibility gaps, which was a significant driver for developing theories of corporate moral responsibility, was initially motivated by concerns for the practical consequences of responsibility gaps on legal practice and the how the resulting loss of a target for liability may lead to harm (eg Matthias 2004; Pettit 2007). I also refer the reader to section 2.1 of Talbert (2024), which describes how several strands of modern research into responsibility practices do not take a purely backwards-looking view of responsibility. I would point out that my argument is likely compatible with several accounts which argue that responsibility practices ought to encourage the development of moral agency. Whether a version of my argument is compatible with a strictly backwards-looking version of responsibility I leave as an open question.

Of course, if I argue that my proposed alterations to responsibility practices are instrumentally desirable because they lead to less wrongful harms, then it leaves me open to the critique that negative side-effects of my proposals overwhelm their benefits. The key benefit that my proposals aim at is the development of *some* genuine corporate moral agency in *some* corporations, and the avoidance of incentives causing its complete removal. It may be argued that corporations' wrongful actions may be better avoided not by trying to promote the development of their moral agency, but instead via regulatory constraints. It may alternatively be argued that the regime of strict liability I envision would cause serious costs to economic productivity and thus common welfare ([eg Schwartz 1992](https://paperpile.com/c/ZMP58v/hPAL/?prefix=eg&ref=10000-words.ghost.io)). These objections highlight that my argument provides only incomplete support for my proposals. It may be a question of empirical research to determine what the right balance is.

### Conclusion

In this essay, I have defined a class of 'self-adjusting agents' which are able to undermine their own moral capacity, and therefore their status as morally responsible agents. I have presented an argument that self-interested self-adjusting agents, of which corporations are the primary example, will tend to remove their moral capacity to avoid harsh sanctions for their actions. Noting the dire consequences of powerful corporations acting in a psychopathic manner, I considered the possibility of adjusting the incentive structure for corporations, leading them to promote, rather than degrade, their own moral responsibility. The key idea is to impose strict liability, where corporations are sanctioned regardless of their awareness or broader moral responsibility.

I considered a range of potential objections to my argument, the strongest of which is that the negative side-effects of strict liability overwhelm the benefits I aim for. This difficulty points at a deeper issue with moral responsibility for corporations. Philosophy about moral responsibility often aims to describe whether responsibility is apt, rather than how it ought to be applied, and aims to conform philosophical conclusions with human intuition. Self-adjusting agents pose a problem for both aims. Their status as morally responsible agents directly responds to the consequences of their moral responsibility, confounding the aim of describing static responsibility practices. Moreover, as I have shown, applying human intuition to corporations (they knew they were doing something bad, so they ought to be punished more severely) leads to negative consequences.

Critics of my argument might argue that imposing strict liability on corporations is naive and has negative side-effects. I would respond that applying human intuition about moral responsibility to corporations is similarly naive, and also has negative side-effects. If we only criticise corporations when they ignore harms they were aware of, we create a blindspot which allows corporations to evade responsibility by simply becoming unaware of their wrongful actions.

## Bibliography

Collins, Stephanie. 2023. "Group Blameworthiness and Group Rights." *Inquiry (Oslo, Norway)*, March, 1–21.

Dennett, Daniel C. 1989. *The Intentional Stance*. The MIT Press, Massachusetts Institute of Technology.

Donaldson, T. 1982. *Corporations and Morality*. Prentice-Hall.

Friedman, Milton. 1970. "The Social Responsibility of Business Is to Increase Its Profits." *The New York Times*, September 13, 1970. [https://www.nytimes.com/1970/09/13/archives/a-friedman-doctrine-the-social-responsibility-of-business-is-to.html](https://www.nytimes.com/1970/09/13/archives/a-friedman-doctrine-the-social-responsibility-of-business-is-to.html)[.](http://paperpile.com/b/ZMP58v/Z6oX?ref=10000-words.ghost.io)

Haan, Niels de. 2021. "Collective Culpable Ignorance." *Thought A Journal of Philosophy* 10 (2): 99–108.

———. 2023. "Collective Moral Agency and Self-Induced Moral Incapacity." *Philosophical Explorations: An International Journal for the Philosophy of Mind and Action* 26 (1): 1–22.

Hindriks, Frank. 2018. "Collective Agency: Moral and Amoral." *Dialectica* 72 (1): 3–23.

Keane, A. C. 2022. "'No Body to Be Kicked or Soul to Be Damned': The Limits of a Legal Fiction." [https://www.hcourt.gov.au/assets/publications/speeches/current-justices/keanej/KeaneJ_17%20May2022.pdf](https://www.hcourt.gov.au/assets/publications/speeches/current-justices/keanej/KeaneJ_17%20May2022.pdf)[.](http://paperpile.com/b/ZMP58v/jJVZ?ref=10000-words.ghost.io)

Kissane, Erin. 2023. "Meta in Myanmar." September 2023. [https://erinkissane.com/meta-in-myanmar-part-i-the-setup](https://erinkissane.com/meta-in-myanmar-part-i-the-setup)[.](http://paperpile.com/b/ZMP58v/kFQq?ref=10000-words.ghost.io)

List, Christian. 2021. "Group Responsibility." In *Oxford Handbook of Moral Responsibility*, edited by Dana Kay Nelkin and Derk Pereboom.

List, Christian, and Philip Pettit. 2011. *The Possibility, Design, and Status of Corporate Agents*. Oxford University Press.

Matthias, Andreas. 2004. "The Responsibility Gap: Ascribing Responsibility for the Actions of Learning Automata." *Ethics and Information Technology* 6 (3): 175–83.

Moen, Lars J. K. 2023. "Groups as Fictional Agents." *Inquiry (Oslo, Norway)* 0 (0): 1–20.

Pettit, Philip. 2007. "Responsibility Incorporated." *Ethics* 117 (2): 171–201.

———. 2014. "Group Agents Are Not Expressive, Pragmatic or Theoretical Fictions." *Erkenntnis* 79 (S9): 1641–62.

Quinton, Anthony. 1976. "Social Objects." *Proceedings of the Aristotelian Society* 76 (1): 1–28.

Rudy-Hiller, Fernando. 2022. "The Epistemic Condition for Moral Responsibility." In *The Stanford Encyclopedia of Philosophy*, edited by Edward N. Zalta and Uri Nodelman. [https://plato.stanford.edu/archives/win2022/entries/moral-responsibility-epistemic](https://plato.stanford.edu/archives/win2022/entries/moral-responsibility-epistemic)[.](http://paperpile.com/b/ZMP58v/MaWtZ?ref=10000-words.ghost.io)

Schwartz, Alan G. 1992. "The Case against Strict Liability." *Fordham Law Review* 60:819.

Shoemaker, David. 2011. "Attributability, Answerability, and Accountability: Toward a Wider Theory of Moral Responsibility." *Ethics* 121 (3): 602–32.

Talbert, Matthew. 2024. "Moral Responsibility." In *The Stanford Encyclopedia of Philosophy*, edited by Edward N. Zalta and Uri Nodelman. [https://plato.stanford.edu/archives/fall2024/entries/moral-responsibility/](https://plato.stanford.edu/archives/fall2024/entries/moral-responsibility/)[.](http://paperpile.com/b/ZMP58v/oJgp?ref=10000-words.ghost.io)

Wells, Georgia, Jeff Horwitz, and Deepa Seetharaman. 2021. "Facebook Knows Instagram Is Toxic for Teen Girls, Company Documents Show." *The Wall Street Journal*, September 14, 2021. [https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739](https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739)[.](http://paperpile.com/b/ZMP58v/lZDu?ref=10000-words.ghost.io)
